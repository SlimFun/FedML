{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88457bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import argparse\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"./../../../../\")))\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"./../../../\")))\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fa4595",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9da6c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 144 from C header, got 152 from PyObject\n",
      "<frozen importlib._bootstrap>:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 144 from C header, got 152 from PyObject\n",
      "<frozen importlib._bootstrap>:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 144 from C header, got 152 from PyObject\n",
      "<frozen importlib._bootstrap>:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 144 from C header, got 152 from PyObject\n"
     ]
    }
   ],
   "source": [
    "from fedml_api.data_preprocessing.cifar10.data_loader import load_partition_data_cifar10\n",
    "from fedml_api.standalone.fedavg.my_model_trainer_classification import MyModelTrainer as MyModelTrainerCLS\n",
    "from fedml_api.model.contrastive_cv.resnet_with_embedding import Resnet56\n",
    "from CovaMNet import CovaMResnet56\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from collections import OrderedDict\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import wandb\n",
    "\n",
    "# from triplet_loss import TripletLoss\n",
    "from hard_triplet_loss import TripletLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c38d330b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mslimfun\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.11.2<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">Cova_hetero_clients10-with_new_own_mean_covaTrue</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/slimfun/cova\" target=\"_blank\">https://wandb.ai/slimfun/cova</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/slimfun/cova/runs/1cbzli4k\" target=\"_blank\">https://wandb.ai/slimfun/cova/runs/1cbzli4k</a><br/>\n",
       "                Run data is saved locally in <code>/home/fw1/nfs_mnt/FedML/fedml_experiments/distributed/contrastive_fed/wandb/run-20211110_194208-1cbzli4k</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = 'cifar10'\n",
    "data_dir = \"./../../../data/cifar10\"\n",
    "partition_method = 'hetero'\n",
    "# partition_method = 'homo'\n",
    "partition_alpha = 0.5\n",
    "client_num_in_total = 10\n",
    "batch_size = 100\n",
    "total_epochs = 500\n",
    "\n",
    "save_model_path = 'model/cs_{0}_{1}_client_{2}_new_own_mean_covaM_epochs_{3}.pt'\n",
    "\n",
    "device = 'cuda:0'\n",
    "with_cova = True\n",
    "\n",
    "wandb.init(\n",
    "            # project=\"federated_nas\",\n",
    "            project=\"cova\",\n",
    "            name=\"Cova_\" + str(partition_method) + \"_clients\" + str(client_num_in_total) + \"-with_new_own_mean_cova\" + str(\n",
    "                with_cova)\n",
    "        )\n",
    "# config = wandb.config\n",
    "# config.learning_rate = 0.01\n",
    "\n",
    "with open(f'dataset_{partition_method}_{client_num_in_total}.pickle', 'rb') as f:\n",
    "    dataset = pickle.load(f)\n",
    "# [train_data_num, test_data_num, train_data_global, test_data_global, \\\n",
    "# #             train_data_local_num_dict, train_data_local_dict, test_data_local_dict, \\\n",
    "# #             class_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67995584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# ls = np.array([int(l) for l in labels])\n",
    "# counter_result = Counter(ls)\n",
    "# print(Counter(ls))\n",
    "# print(dataset[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a8c4487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Resnet56(class_num=dataset[-1], neck='bnneck')\n",
    "# model.load_state_dict(torch.load('model/cs_3_homo_client_0_oral_epochs_200.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6474ae2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a16a03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cal_covariance(input):\n",
    "\n",
    "#     CovaMatrix_list = []\n",
    "#     mean_list = []\n",
    "#     for i in range(len(input)):\n",
    "#         support_set_sam = input[i]\n",
    "#         support_set_sam = torch.unsqueeze(support_set_sam, 0)\n",
    "#         B, C, h, w = support_set_sam.size()\n",
    "        \n",
    "\n",
    "#         support_set_sam = support_set_sam.permute(1, 0, 2, 3)\n",
    "#         support_set_sam = support_set_sam.contiguous().view(C, -1)\n",
    "\n",
    "#         mean_support = torch.mean(support_set_sam, 1, True)\n",
    "#         mean_list.append(mean_support)\n",
    "\n",
    "#         support_set_sam = support_set_sam-mean_support\n",
    "\n",
    "#         covariance_matrix = support_set_sam@torch.transpose(support_set_sam, 0, 1)\n",
    "#         covariance_matrix = torch.div(covariance_matrix, h*w*B-1)\n",
    "#         CovaMatrix_list.append(covariance_matrix)\n",
    "\n",
    "#     return CovaMatrix_list, mean_list\n",
    "        \n",
    "        \n",
    "\n",
    "# cl = [torch.zeros((256,256)) for i in range(10)]\n",
    "# ml = [torch.zeros((256,64)) for i in range(10)]\n",
    "# lbd = 0.999\n",
    "# labels = []\n",
    "# def extract_features(model, data_loader, device):\n",
    "#     model.to(device)\n",
    "#     model.eval()\n",
    "    \n",
    "#     features = []\n",
    "    \n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         for batch_idx, (x, l) in enumerate(data_loader):\n",
    "#             x, l = x.to(device), l.to(device)\n",
    "            \n",
    "#             score, feats = model(x)\n",
    "#             covaM_list, mean_list = cal_covariance(feats)\n",
    "#             for covaM, f, label in zip(covaM_list, feats, l):\n",
    "#                 labels.append(label.cpu())\n",
    "#                 for i in range(len(cl)):\n",
    "#                     if label.data.cpu() == i:\n",
    "#                         cl[i] = lbd * cl[i] + (1-lbd) * covaM.cpu()\n",
    "#                         f = torch.unsqueeze(f, 0)\n",
    "#                         B, C, h, w = f.size()\n",
    "\n",
    "#                         f = f.permute(1, 0, 2, 3)\n",
    "#                         f = f.contiguous().view(C, -1)\n",
    "#                         ml[i] = lbd * ml[i] + (1-lbd) * f.cpu()\n",
    "\n",
    "# # metrics = test(model, dataset[3], device)\n",
    "# # test_correct = metrics['test_correct']/metrics['test_total']\n",
    "# # test_loss = metrics['test_loss']/metrics['test_total']\n",
    "# # print(metrics['test_total'])\n",
    "# # print(f'test_correct: {test_correct}; test_loss: {test_loss}')\n",
    "# # extract_features(model, dataset[2], device)\n",
    "# # covaMs_means = [cl, ml]\n",
    "# # with open(f'class_covaMs_means.pickle', 'wb') as f:\n",
    "# #     pickle.dump(covaMs_means, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a55b468c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f'class_covaMs_means.pickle', 'rb') as f:\n",
    "with open(f'new_covaM_mean.pickle', 'rb') as f:\n",
    "    cms = pickle.load(f)\n",
    "    \n",
    "for i in range(len(cms[0])):\n",
    "    cms[0][i] = cms[0][i].to(device)\n",
    "#     cms[0][i] = torch.eye(256).to(device) / 256\n",
    "    \n",
    "# for i in range(len(cms[1])):\n",
    "#     cms[1][i] = cms[1][i].to(device)\n",
    "# print(cms[0][0] - cl[0])\n",
    "# print(cms[1][1] - ml[1])\n",
    "# from collections import Counter\n",
    "# ls = np.array([int(l) for l in labels])\n",
    "# counter_result = Counter(ls)\n",
    "# print(Counter(ls))\n",
    "# Counter({1: 1145, 2: 1138, 0: 797, 3: 661, 4: 555, 5: 539, 8: 227, 7: 38})\n",
    "# print(len(cms[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5e0fd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Client(object):\n",
    "    def __init__(self, client_index, train_data_local_dict, train_data_local_num_dict, test_data_local_dict, device, model):\n",
    "        self.id = client_index\n",
    "        self.train_data = train_data_local_dict[self.id]\n",
    "        self.local_sample_number = train_data_local_num_dict[self.id]\n",
    "        self.test_local = test_data_local_dict[self.id]\n",
    "        \n",
    "        self.device = device\n",
    "        self.model = model\n",
    "model1 = CovaMResnet56(class_num=dataset[-1], neck='bnneck', with_cova=with_cova)\n",
    "client_1 = Client(0, dataset[5], dataset[4], dataset[6], device, model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7edaa339",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_data, device):\n",
    "    cl = cms[0]\n",
    "    ml = cms[1]\n",
    "#     support_ml = []\n",
    "#     for i in range(10):\n",
    "#         support_ml.append(cms[1][i].to(device))\n",
    "#     ml = cms[1]\n",
    "#     print(cms[0][0])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    metrics = {\n",
    "        'test_correct': 0,\n",
    "        'test_loss': 0,\n",
    "        'test_total': 0,\n",
    "        'correct_cova': 0\n",
    "    }\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (x, target) in enumerate(test_data):\n",
    "            x = x.to(device)\n",
    "            target = target.to(device)\n",
    "            support_ml = []\n",
    "            for l in target:\n",
    "                support_ml.append(ml[l.data].to(device))\n",
    "            pred, pred_ce_cova, feat = model(x, cl, ml=support_ml)\n",
    "            loss = criterion(pred, target)\n",
    "            \n",
    "#             loss_ce_cova = criterion(pred_ce_cova, target)\n",
    "\n",
    "            _, predicted = torch.max(pred, -1)\n",
    "            _, predicted_ce_cova = torch.max(pred_ce_cova, -1)\n",
    "            correct = predicted.eq(target).sum()\n",
    "            correct_ce_cova = predicted_ce_cova.eq(target).sum()\n",
    "\n",
    "            metrics['test_correct'] += correct.item()\n",
    "            metrics['test_loss'] += loss.item() * target.size(0)\n",
    "            metrics['test_total'] += target.size(0)\n",
    "            metrics['correct_cova'] += correct_ce_cova.item()\n",
    "            \n",
    "    return metrics\n",
    "\n",
    "def train_model(client, epochs):\n",
    "#     learning_rate = 0.001\n",
    "#     wd = 0.0001\n",
    "#     learning_rate = 0.00035\n",
    "#     wd = 0.0005\n",
    "\n",
    "    cl = cms[0]\n",
    "    ml = cms[1]\n",
    "    \n",
    "    margin = 0.3\n",
    "    \n",
    "    client.model.to(client.device)\n",
    "    client.model.train()\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    mse_loss = nn.MSELoss().to(device)\n",
    "    \n",
    "#     curr_lr = learning_rate\n",
    "#     optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, client.model.parameters()), lr=curr_lr,\n",
    "#                                          weight_decay=wd, amsgrad=True)\n",
    "    optimizer = torch.optim.SGD(client.model.parameters(), lr=0.1,\n",
    "                      momentum=0.9, weight_decay=5e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "\n",
    "    epoch_loss = []\n",
    "    total_step = len(client.train_data)\n",
    "#     wandb.watch(client.model, log='all')\n",
    "    for epoch in range(epochs):\n",
    "        client.model.train()\n",
    "        batch_loss = []\n",
    "        for batch_idx, (x, labels) in enumerate(client.train_data):\n",
    "            x, labels = x.to(device), labels.to(device)\n",
    "#             print(labels.shape)\n",
    "            client.model.zero_grad()\n",
    "            support_ml = []\n",
    "            for l in labels:\n",
    "                # B, 256, 64\n",
    "                support_ml.append(ml[l.data].to(device))\n",
    "            cls_score, cova_score, feat = client.model(x, support_covas=cl, ml=support_ml)\n",
    "#             print(score.shape)\n",
    "#             print(cova_score)\n",
    "            loss = criterion(cls_score, labels)\n",
    "            loss = loss.to(device) + criterion(cova_score, labels).to(device)\n",
    "            loss.backward()\n",
    "        \n",
    "#             torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            optimizer.step()\n",
    "            batch_loss.append(loss.item())\n",
    "            \n",
    "#         if epoch % 50 == 0:\n",
    "#             torch.save(client.model.state_dict(), str.format(save_model_path, client_num_in_total, partition_method, client.id, epoch))\n",
    "        epoch_loss.append(sum(batch_loss) / len(batch_loss))\n",
    "        scheduler.step()\n",
    "        print('Client Index = {}\\tEpoch: {}\\tLoss: {:.6f}'.format(\n",
    "            client.id, epoch, sum(batch_loss) / len(batch_loss)))\n",
    "        \n",
    "        metrics = test(client.model, client.test_local, client.device)\n",
    "        test_correct = metrics['test_correct']/metrics['test_total']\n",
    "        test_loss = metrics['test_loss']/metrics['test_total']\n",
    "        correct_ce_cova = metrics['correct_cova']/metrics['test_total']\n",
    "#         print(metrics['test_total'])\n",
    "        print(f'test_correct: {test_correct}; test_loss: {test_loss}')\n",
    "        wandb.log({\n",
    "#             'epoch' : epoch,\n",
    "            'train_loss': sum(batch_loss) / len(batch_loss),\n",
    "            'test_correct' : test_correct,\n",
    "            'test_loss' : test_loss,\n",
    "            'correct_cova' : correct_ce_cova\n",
    "        }, step=epoch)\n",
    "        \n",
    "    torch.save(client.model.state_dict(), str.format(save_model_path, client_num_in_total, partition_method, client.id, epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78d69b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client Index = 0\tEpoch: 0\tLoss: 4.786476\n",
      "test_correct: 0.1586; test_loss: 3.466472320556641\n",
      "Client Index = 0\tEpoch: 1\tLoss: 3.859555\n",
      "test_correct: 0.2135; test_loss: 3.184601199626923\n",
      "Client Index = 0\tEpoch: 2\tLoss: 3.600190\n",
      "test_correct: 0.2101; test_loss: 2.486977307796478\n",
      "Client Index = 0\tEpoch: 3\tLoss: 3.407322\n",
      "test_correct: 0.2278; test_loss: 2.368880548477173\n",
      "Client Index = 0\tEpoch: 4\tLoss: 3.154656\n",
      "test_correct: 0.2621; test_loss: 2.2476958739757538\n",
      "Client Index = 0\tEpoch: 5\tLoss: 3.122354\n",
      "test_correct: 0.2488; test_loss: 2.251830898523331\n",
      "Client Index = 0\tEpoch: 6\tLoss: 2.996206\n",
      "test_correct: 0.2196; test_loss: 2.4497832584381105\n",
      "Client Index = 0\tEpoch: 7\tLoss: 2.925520\n",
      "test_correct: 0.2438; test_loss: 2.474561083316803\n",
      "Client Index = 0\tEpoch: 8\tLoss: 2.841355\n",
      "test_correct: 0.2722; test_loss: 2.2827549982070923\n",
      "Client Index = 0\tEpoch: 9\tLoss: 2.787936\n",
      "test_correct: 0.2526; test_loss: 2.2142521154880526\n",
      "Client Index = 0\tEpoch: 10\tLoss: 2.790414\n",
      "test_correct: 0.2686; test_loss: 2.3162660813331604\n",
      "Client Index = 0\tEpoch: 11\tLoss: 2.737166\n",
      "test_correct: 0.2733; test_loss: 2.290895973443985\n",
      "Client Index = 0\tEpoch: 12\tLoss: 2.679887\n",
      "test_correct: 0.3016; test_loss: 2.1771817207336426\n",
      "Client Index = 0\tEpoch: 13\tLoss: 2.665149\n",
      "test_correct: 0.2715; test_loss: 2.5973263812065124\n",
      "Client Index = 0\tEpoch: 14\tLoss: 2.627249\n",
      "test_correct: 0.2379; test_loss: 2.3527265214920043\n",
      "Client Index = 0\tEpoch: 15\tLoss: 2.577050\n",
      "test_correct: 0.3071; test_loss: 2.3104991841316225\n",
      "Client Index = 0\tEpoch: 16\tLoss: 2.593325\n",
      "test_correct: 0.3055; test_loss: 2.4500865960121154\n",
      "Client Index = 0\tEpoch: 17\tLoss: 2.559654\n",
      "test_correct: 0.3211; test_loss: 2.2207971417903902\n",
      "Client Index = 0\tEpoch: 18\tLoss: 2.509663\n",
      "test_correct: 0.3053; test_loss: 2.3688464689254762\n",
      "Client Index = 0\tEpoch: 19\tLoss: 2.515086\n",
      "test_correct: 0.3092; test_loss: 2.370122467279434\n",
      "Client Index = 0\tEpoch: 20\tLoss: 2.490330\n",
      "test_correct: 0.3315; test_loss: 2.452260092496872\n",
      "Client Index = 0\tEpoch: 21\tLoss: 2.477214\n",
      "test_correct: 0.3241; test_loss: 2.2527893841266633\n",
      "Client Index = 0\tEpoch: 22\tLoss: 2.426417\n",
      "test_correct: 0.2946; test_loss: 2.3835588133335115\n",
      "Client Index = 0\tEpoch: 23\tLoss: 2.405922\n",
      "test_correct: 0.3388; test_loss: 2.265241069793701\n",
      "Client Index = 0\tEpoch: 24\tLoss: 2.342945\n",
      "test_correct: 0.3549; test_loss: 2.351913493871689\n",
      "Client Index = 0\tEpoch: 25\tLoss: 2.321135\n",
      "test_correct: 0.3568; test_loss: 2.279589341878891\n",
      "Client Index = 0\tEpoch: 26\tLoss: 2.330780\n",
      "test_correct: 0.3563; test_loss: 2.2701305818557738\n",
      "Client Index = 0\tEpoch: 27\tLoss: 2.319533\n",
      "test_correct: 0.3617; test_loss: 2.3422143399715423\n",
      "Client Index = 0\tEpoch: 28\tLoss: 2.265229\n",
      "test_correct: 0.379; test_loss: 2.1594387066364287\n",
      "Client Index = 0\tEpoch: 29\tLoss: 2.258728\n",
      "test_correct: 0.3573; test_loss: 2.2335859513282776\n",
      "Client Index = 0\tEpoch: 30\tLoss: 2.221769\n",
      "test_correct: 0.3531; test_loss: 2.3203032505512238\n",
      "Client Index = 0\tEpoch: 31\tLoss: 2.193562\n",
      "test_correct: 0.3396; test_loss: 2.624102690219879\n",
      "Client Index = 0\tEpoch: 32\tLoss: 2.154413\n",
      "test_correct: 0.3892; test_loss: 2.2601217293739317\n",
      "Client Index = 0\tEpoch: 33\tLoss: 2.095514\n",
      "test_correct: 0.4019; test_loss: 2.243435640335083\n",
      "Client Index = 0\tEpoch: 34\tLoss: 2.118432\n",
      "test_correct: 0.3015; test_loss: 2.4777773678302766\n",
      "Client Index = 0\tEpoch: 35\tLoss: 2.058324\n",
      "test_correct: 0.3961; test_loss: 2.376405506134033\n",
      "Client Index = 0\tEpoch: 36\tLoss: 2.049077\n",
      "test_correct: 0.3742; test_loss: 2.1828860986232757\n",
      "Client Index = 0\tEpoch: 37\tLoss: 1.994903\n",
      "test_correct: 0.3801; test_loss: 2.376811159849167\n",
      "Client Index = 0\tEpoch: 38\tLoss: 2.009959\n",
      "test_correct: 0.4046; test_loss: 2.191936889886856\n",
      "Client Index = 0\tEpoch: 39\tLoss: 2.007778\n",
      "test_correct: 0.3938; test_loss: 2.2341954421997072\n",
      "Client Index = 0\tEpoch: 40\tLoss: 1.939535\n",
      "test_correct: 0.3636; test_loss: 2.3121106815338135\n",
      "Client Index = 0\tEpoch: 41\tLoss: 1.912303\n",
      "test_correct: 0.4028; test_loss: 2.3050971066951753\n",
      "Client Index = 0\tEpoch: 42\tLoss: 1.924291\n",
      "test_correct: 0.4067; test_loss: 2.23111362695694\n",
      "Client Index = 0\tEpoch: 43\tLoss: 1.862796\n",
      "test_correct: 0.3634; test_loss: 2.575344967842102\n",
      "Client Index = 0\tEpoch: 44\tLoss: 1.858202\n",
      "test_correct: 0.425; test_loss: 2.1930642914772034\n",
      "Client Index = 0\tEpoch: 45\tLoss: 1.842974\n",
      "test_correct: 0.4263; test_loss: 2.1247420608997345\n",
      "Client Index = 0\tEpoch: 46\tLoss: 1.834596\n",
      "test_correct: 0.4255; test_loss: 2.26909166097641\n",
      "Client Index = 0\tEpoch: 47\tLoss: 1.777982\n",
      "test_correct: 0.4265; test_loss: 2.2555012953281404\n",
      "Client Index = 0\tEpoch: 48\tLoss: 1.840956\n",
      "test_correct: 0.4238; test_loss: 2.1712376403808595\n",
      "Client Index = 0\tEpoch: 49\tLoss: 1.794145\n",
      "test_correct: 0.3779; test_loss: 2.515705064535141\n",
      "Client Index = 0\tEpoch: 50\tLoss: 1.785175\n",
      "test_correct: 0.4197; test_loss: 2.2455771136283875\n",
      "Client Index = 0\tEpoch: 51\tLoss: 1.734332\n",
      "test_correct: 0.4272; test_loss: 2.3369808995723726\n",
      "Client Index = 0\tEpoch: 52\tLoss: 1.763652\n",
      "test_correct: 0.4139; test_loss: 2.277437974214554\n",
      "Client Index = 0\tEpoch: 53\tLoss: 1.739470\n",
      "test_correct: 0.4356; test_loss: 2.258720499277115\n",
      "Client Index = 0\tEpoch: 54\tLoss: 1.741858\n",
      "test_correct: 0.4546; test_loss: 2.2041433274745943\n",
      "Client Index = 0\tEpoch: 55\tLoss: 1.691960\n",
      "test_correct: 0.4149; test_loss: 2.5440468072891234\n",
      "Client Index = 0\tEpoch: 56\tLoss: 1.646036\n",
      "test_correct: 0.4507; test_loss: 2.26341868519783\n",
      "Client Index = 0\tEpoch: 57\tLoss: 1.663801\n",
      "test_correct: 0.4197; test_loss: 2.510276908874512\n",
      "Client Index = 0\tEpoch: 58\tLoss: 1.656670\n",
      "test_correct: 0.4327; test_loss: 2.2460132837295532\n",
      "Client Index = 0\tEpoch: 59\tLoss: 1.638794\n",
      "test_correct: 0.3847; test_loss: 2.530104459524155\n",
      "Client Index = 0\tEpoch: 60\tLoss: 1.622155\n",
      "test_correct: 0.4296; test_loss: 2.4275447487831117\n",
      "Client Index = 0\tEpoch: 61\tLoss: 1.628132\n",
      "test_correct: 0.4279; test_loss: 2.601600410938263\n",
      "Client Index = 0\tEpoch: 62\tLoss: 1.592071\n",
      "test_correct: 0.4565; test_loss: 2.237097051143646\n",
      "Client Index = 0\tEpoch: 63\tLoss: 1.546514\n",
      "test_correct: 0.4523; test_loss: 2.3609899353981016\n",
      "Client Index = 0\tEpoch: 64\tLoss: 1.559252\n",
      "test_correct: 0.4254; test_loss: 2.571653617620468\n",
      "Client Index = 0\tEpoch: 65\tLoss: 1.578180\n",
      "test_correct: 0.4539; test_loss: 2.215648194551468\n",
      "Client Index = 0\tEpoch: 66\tLoss: 1.493100\n",
      "test_correct: 0.3836; test_loss: 3.101652195453644\n",
      "Client Index = 0\tEpoch: 67\tLoss: 1.495799\n",
      "test_correct: 0.4388; test_loss: 2.5963179051876066\n",
      "Client Index = 0\tEpoch: 68\tLoss: 1.494370\n",
      "test_correct: 0.4268; test_loss: 2.6820287346839904\n",
      "Client Index = 0\tEpoch: 69\tLoss: 1.475119\n",
      "test_correct: 0.3792; test_loss: 3.0493754053115847\n",
      "Client Index = 0\tEpoch: 70\tLoss: 1.446378\n",
      "test_correct: 0.4717; test_loss: 2.360618752241135\n",
      "Client Index = 0\tEpoch: 71\tLoss: 1.436039\n",
      "test_correct: 0.4717; test_loss: 2.251348605155945\n",
      "Client Index = 0\tEpoch: 72\tLoss: 1.429921\n",
      "test_correct: 0.4545; test_loss: 2.4521098697185515\n",
      "Client Index = 0\tEpoch: 73\tLoss: 1.445584\n",
      "test_correct: 0.4703; test_loss: 2.270256803035736\n",
      "Client Index = 0\tEpoch: 74\tLoss: 1.393822\n",
      "test_correct: 0.4714; test_loss: 2.364440460205078\n",
      "Client Index = 0\tEpoch: 75\tLoss: 1.367632\n",
      "test_correct: 0.4842; test_loss: 2.391093828678131\n",
      "Client Index = 0\tEpoch: 76\tLoss: 1.360420\n",
      "test_correct: 0.4957; test_loss: 2.3912434542179106\n",
      "Client Index = 0\tEpoch: 77\tLoss: 1.367096\n",
      "test_correct: 0.474; test_loss: 2.402555558681488\n",
      "Client Index = 0\tEpoch: 78\tLoss: 1.340439\n",
      "test_correct: 0.5154; test_loss: 2.0568538200855255\n",
      "Client Index = 0\tEpoch: 79\tLoss: 1.321734\n",
      "test_correct: 0.4766; test_loss: 2.5043799793720245\n",
      "Client Index = 0\tEpoch: 80\tLoss: 1.348291\n",
      "test_correct: 0.4964; test_loss: 2.2721892738342286\n",
      "Client Index = 0\tEpoch: 81\tLoss: 1.343404\n",
      "test_correct: 0.4802; test_loss: 2.283669939041138\n",
      "Client Index = 0\tEpoch: 82\tLoss: 1.331480\n",
      "test_correct: 0.5051; test_loss: 2.2226276338100432\n",
      "Client Index = 0\tEpoch: 83\tLoss: 1.269360\n",
      "test_correct: 0.431; test_loss: 2.756294709444046\n",
      "Client Index = 0\tEpoch: 84\tLoss: 1.273278\n",
      "test_correct: 0.4905; test_loss: 2.45392538189888\n",
      "Client Index = 0\tEpoch: 85\tLoss: 1.220774\n",
      "test_correct: 0.5174; test_loss: 2.225797369480133\n",
      "Client Index = 0\tEpoch: 86\tLoss: 1.254698\n",
      "test_correct: 0.4819; test_loss: 2.4034298706054686\n",
      "Client Index = 0\tEpoch: 87\tLoss: 1.271050\n",
      "test_correct: 0.4677; test_loss: 2.755287742614746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client Index = 0\tEpoch: 88\tLoss: 1.201507\n",
      "test_correct: 0.5023; test_loss: 2.1818998301029207\n",
      "Client Index = 0\tEpoch: 89\tLoss: 1.169179\n",
      "test_correct: 0.5255; test_loss: 2.1321379005908967\n",
      "Client Index = 0\tEpoch: 90\tLoss: 1.206404\n",
      "test_correct: 0.5248; test_loss: 2.1458536636829377\n",
      "Client Index = 0\tEpoch: 91\tLoss: 1.203359\n",
      "test_correct: 0.5115; test_loss: 2.2069888985157013\n",
      "Client Index = 0\tEpoch: 92\tLoss: 1.144485\n",
      "test_correct: 0.497; test_loss: 2.4136093413829802\n",
      "Client Index = 0\tEpoch: 93\tLoss: 1.170703\n",
      "test_correct: 0.5014; test_loss: 2.432875248193741\n",
      "Client Index = 0\tEpoch: 94\tLoss: 1.176800\n",
      "test_correct: 0.5273; test_loss: 2.1364772546291353\n",
      "Client Index = 0\tEpoch: 95\tLoss: 1.137306\n",
      "test_correct: 0.4821; test_loss: 2.3501340627670286\n",
      "Client Index = 0\tEpoch: 96\tLoss: 1.044269\n",
      "test_correct: 0.5298; test_loss: 2.245266420841217\n",
      "Client Index = 0\tEpoch: 97\tLoss: 1.142396\n",
      "test_correct: 0.5191; test_loss: 2.2881109929084777\n",
      "Client Index = 0\tEpoch: 98\tLoss: 1.164139\n",
      "test_correct: 0.5364; test_loss: 2.0942695331573487\n",
      "Client Index = 0\tEpoch: 99\tLoss: 1.041273\n",
      "test_correct: 0.4567; test_loss: 2.7571326804161074\n",
      "Client Index = 0\tEpoch: 100\tLoss: 1.081543\n",
      "test_correct: 0.5239; test_loss: 2.2809209883213044\n",
      "Client Index = 0\tEpoch: 101\tLoss: 1.054482\n",
      "test_correct: 0.5606; test_loss: 2.0887009477615357\n",
      "Client Index = 0\tEpoch: 102\tLoss: 1.034497\n",
      "test_correct: 0.5158; test_loss: 2.5481640458106996\n",
      "Client Index = 0\tEpoch: 103\tLoss: 1.051836\n",
      "test_correct: 0.52; test_loss: 2.412585519552231\n",
      "Client Index = 0\tEpoch: 104\tLoss: 1.071006\n",
      "test_correct: 0.5451; test_loss: 2.2318922591209414\n",
      "Client Index = 0\tEpoch: 105\tLoss: 0.995505\n",
      "test_correct: 0.5406; test_loss: 2.281131205558777\n",
      "Client Index = 0\tEpoch: 106\tLoss: 1.013077\n",
      "test_correct: 0.5358; test_loss: 2.1563593447208405\n",
      "Client Index = 0\tEpoch: 107\tLoss: 0.983524\n",
      "test_correct: 0.5318; test_loss: 2.2780085504055023\n",
      "Client Index = 0\tEpoch: 108\tLoss: 1.028992\n",
      "test_correct: 0.5324; test_loss: 2.3179427540302275\n",
      "Client Index = 0\tEpoch: 109\tLoss: 0.970065\n",
      "test_correct: 0.5418; test_loss: 2.223046153783798\n",
      "Client Index = 0\tEpoch: 110\tLoss: 0.996317\n",
      "test_correct: 0.5443; test_loss: 2.323571187257767\n",
      "Client Index = 0\tEpoch: 111\tLoss: 0.921079\n",
      "test_correct: 0.5526; test_loss: 2.25385324716568\n",
      "Client Index = 0\tEpoch: 112\tLoss: 0.952967\n",
      "test_correct: 0.5413; test_loss: 2.3271952259540556\n",
      "Client Index = 0\tEpoch: 113\tLoss: 0.907525\n",
      "test_correct: 0.5431; test_loss: 2.3344324135780337\n",
      "Client Index = 0\tEpoch: 114\tLoss: 0.920548\n",
      "test_correct: 0.5433; test_loss: 2.383782023191452\n",
      "Client Index = 0\tEpoch: 115\tLoss: 0.894405\n",
      "test_correct: 0.5565; test_loss: 2.340669560432434\n",
      "Client Index = 0\tEpoch: 116\tLoss: 0.907257\n",
      "test_correct: 0.5175; test_loss: 2.453089997768402\n",
      "Client Index = 0\tEpoch: 117\tLoss: 0.828918\n",
      "test_correct: 0.5438; test_loss: 2.3451241493225097\n",
      "Client Index = 0\tEpoch: 118\tLoss: 0.830491\n",
      "test_correct: 0.5267; test_loss: 2.4699660778045653\n",
      "Client Index = 0\tEpoch: 119\tLoss: 0.862757\n",
      "test_correct: 0.5341; test_loss: 2.4200184106826783\n",
      "Client Index = 0\tEpoch: 120\tLoss: 0.855685\n",
      "test_correct: 0.5306; test_loss: 2.5739446759223936\n",
      "Client Index = 0\tEpoch: 121\tLoss: 0.822976\n",
      "test_correct: 0.5032; test_loss: 2.6928282487392425\n",
      "Client Index = 0\tEpoch: 122\tLoss: 0.834123\n",
      "test_correct: 0.5074; test_loss: 2.6254196763038635\n",
      "Client Index = 0\tEpoch: 123\tLoss: 0.807688\n",
      "test_correct: 0.4897; test_loss: 2.948836518526077\n",
      "Client Index = 0\tEpoch: 124\tLoss: 0.819121\n",
      "test_correct: 0.5663; test_loss: 2.231447831392288\n",
      "Client Index = 0\tEpoch: 125\tLoss: 0.763677\n",
      "test_correct: 0.581; test_loss: 2.355599503517151\n",
      "Client Index = 0\tEpoch: 126\tLoss: 0.695353\n",
      "test_correct: 0.5749; test_loss: 2.258949249982834\n",
      "Client Index = 0\tEpoch: 127\tLoss: 0.797031\n",
      "test_correct: 0.5419; test_loss: 2.610957884788513\n",
      "Client Index = 0\tEpoch: 128\tLoss: 0.745397\n",
      "test_correct: 0.5613; test_loss: 2.365933814048767\n",
      "Client Index = 0\tEpoch: 129\tLoss: 0.750645\n",
      "test_correct: 0.5855; test_loss: 2.268532111644745\n",
      "Client Index = 0\tEpoch: 130\tLoss: 0.719052\n",
      "test_correct: 0.5437; test_loss: 2.617139754295349\n",
      "Client Index = 0\tEpoch: 131\tLoss: 0.693373\n",
      "test_correct: 0.5585; test_loss: 2.3788780009746553\n",
      "Client Index = 0\tEpoch: 132\tLoss: 0.703199\n",
      "test_correct: 0.5736; test_loss: 2.364384958744049\n",
      "Client Index = 0\tEpoch: 133\tLoss: 0.678429\n",
      "test_correct: 0.542; test_loss: 2.6910728287696837\n",
      "Client Index = 0\tEpoch: 134\tLoss: 0.707344\n",
      "test_correct: 0.5761; test_loss: 2.2945547819137575\n",
      "Client Index = 0\tEpoch: 135\tLoss: 0.674023\n",
      "test_correct: 0.5681; test_loss: 2.463312042951584\n",
      "Client Index = 0\tEpoch: 136\tLoss: 0.647058\n",
      "test_correct: 0.5695; test_loss: 2.2784295010566713\n",
      "Client Index = 0\tEpoch: 137\tLoss: 0.645255\n",
      "test_correct: 0.5204; test_loss: 2.7457605981826783\n",
      "Client Index = 0\tEpoch: 138\tLoss: 0.634039\n",
      "test_correct: 0.5481; test_loss: 2.616002086400986\n",
      "Client Index = 0\tEpoch: 139\tLoss: 0.622568\n",
      "test_correct: 0.5719; test_loss: 2.5027041459083557\n",
      "Client Index = 0\tEpoch: 140\tLoss: 0.604426\n",
      "test_correct: 0.5342; test_loss: 2.7643326044082643\n",
      "Client Index = 0\tEpoch: 141\tLoss: 0.563576\n",
      "test_correct: 0.5613; test_loss: 2.5558808290958406\n",
      "Client Index = 0\tEpoch: 142\tLoss: 0.599851\n",
      "test_correct: 0.5635; test_loss: 2.5353264904022215\n",
      "Client Index = 0\tEpoch: 143\tLoss: 0.593814\n",
      "test_correct: 0.5635; test_loss: 2.61000048160553\n",
      "Client Index = 0\tEpoch: 144\tLoss: 0.553462\n",
      "test_correct: 0.5836; test_loss: 2.393522229194641\n",
      "Client Index = 0\tEpoch: 145\tLoss: 0.547837\n",
      "test_correct: 0.5737; test_loss: 2.6216377770900725\n",
      "Client Index = 0\tEpoch: 146\tLoss: 0.540302\n",
      "test_correct: 0.5834; test_loss: 2.414484484195709\n",
      "Client Index = 0\tEpoch: 147\tLoss: 0.507332\n",
      "test_correct: 0.5857; test_loss: 2.4294158136844635\n",
      "Client Index = 0\tEpoch: 148\tLoss: 0.504882\n",
      "test_correct: 0.5584; test_loss: 2.7314516210556032\n",
      "Client Index = 0\tEpoch: 149\tLoss: 0.520803\n",
      "test_correct: 0.5884; test_loss: 2.5073660790920256\n",
      "Client Index = 0\tEpoch: 150\tLoss: 0.505622\n",
      "test_correct: 0.5861; test_loss: 2.5153066217899323\n",
      "Client Index = 0\tEpoch: 151\tLoss: 0.444442\n",
      "test_correct: 0.5598; test_loss: 2.612418085336685\n",
      "Client Index = 0\tEpoch: 152\tLoss: 0.466766\n",
      "test_correct: 0.5852; test_loss: 2.5256019496917723\n",
      "Client Index = 0\tEpoch: 153\tLoss: 0.477317\n",
      "test_correct: 0.5913; test_loss: 2.557238355875015\n",
      "Client Index = 0\tEpoch: 154\tLoss: 0.456203\n",
      "test_correct: 0.5879; test_loss: 2.4803988873958587\n",
      "Client Index = 0\tEpoch: 155\tLoss: 0.429375\n",
      "test_correct: 0.5845; test_loss: 2.642222819328308\n",
      "Client Index = 0\tEpoch: 156\tLoss: 0.403093\n",
      "test_correct: 0.5672; test_loss: 2.71533970952034\n",
      "Client Index = 0\tEpoch: 157\tLoss: 0.400016\n",
      "test_correct: 0.5897; test_loss: 2.585763404369354\n",
      "Client Index = 0\tEpoch: 158\tLoss: 0.396467\n",
      "test_correct: 0.592; test_loss: 2.5767759931087495\n",
      "Client Index = 0\tEpoch: 159\tLoss: 0.381581\n",
      "test_correct: 0.5843; test_loss: 2.6029623591899873\n",
      "Client Index = 0\tEpoch: 160\tLoss: 0.376079\n",
      "test_correct: 0.6015; test_loss: 2.4680529057979586\n",
      "Client Index = 0\tEpoch: 161\tLoss: 0.350024\n",
      "test_correct: 0.5844; test_loss: 2.64388546705246\n",
      "Client Index = 0\tEpoch: 162\tLoss: 0.384165\n",
      "test_correct: 0.5903; test_loss: 2.6279714846611024\n",
      "Client Index = 0\tEpoch: 163\tLoss: 0.383518\n",
      "test_correct: 0.5891; test_loss: 2.5277649998664855\n",
      "Client Index = 0\tEpoch: 164\tLoss: 0.341739\n",
      "test_correct: 0.5914; test_loss: 2.6014645433425905\n",
      "Client Index = 0\tEpoch: 165\tLoss: 0.332362\n",
      "test_correct: 0.5857; test_loss: 2.6428208541870117\n",
      "Client Index = 0\tEpoch: 166\tLoss: 0.303731\n",
      "test_correct: 0.5917; test_loss: 2.6340490114688873\n",
      "Client Index = 0\tEpoch: 167\tLoss: 0.332536\n",
      "test_correct: 0.5874; test_loss: 2.6727666807174684\n",
      "Client Index = 0\tEpoch: 168\tLoss: 0.289067\n",
      "test_correct: 0.5947; test_loss: 2.5850265765190126\n",
      "Client Index = 0\tEpoch: 169\tLoss: 0.290937\n",
      "test_correct: 0.5871; test_loss: 2.697007666826248\n",
      "Client Index = 0\tEpoch: 170\tLoss: 0.271055\n",
      "test_correct: 0.5825; test_loss: 2.7469731998443603\n",
      "Client Index = 0\tEpoch: 171\tLoss: 0.276906\n",
      "test_correct: 0.5941; test_loss: 2.556938968896866\n",
      "Client Index = 0\tEpoch: 172\tLoss: 0.261597\n",
      "test_correct: 0.5889; test_loss: 2.6893874549865724\n",
      "Client Index = 0\tEpoch: 173\tLoss: 0.284126\n",
      "test_correct: 0.5859; test_loss: 2.7045218431949616\n",
      "Client Index = 0\tEpoch: 174\tLoss: 0.263103\n",
      "test_correct: 0.5917; test_loss: 2.665936748981476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client Index = 0\tEpoch: 175\tLoss: 0.246662\n",
      "test_correct: 0.5917; test_loss: 2.6711158573627474\n",
      "Client Index = 0\tEpoch: 176\tLoss: 0.224142\n",
      "test_correct: 0.5939; test_loss: 2.6914417803287507\n",
      "Client Index = 0\tEpoch: 177\tLoss: 0.235619\n",
      "test_correct: 0.5969; test_loss: 2.683759335279465\n",
      "Client Index = 0\tEpoch: 178\tLoss: 0.240055\n",
      "test_correct: 0.5982; test_loss: 2.643469064235687\n",
      "Client Index = 0\tEpoch: 179\tLoss: 0.220918\n",
      "test_correct: 0.5879; test_loss: 2.743509718179703\n",
      "Client Index = 0\tEpoch: 180\tLoss: 0.240158\n",
      "test_correct: 0.5998; test_loss: 2.660547289848328\n",
      "Client Index = 0\tEpoch: 181\tLoss: 0.235696\n",
      "test_correct: 0.5911; test_loss: 2.752983659505844\n",
      "Client Index = 0\tEpoch: 182\tLoss: 0.222149\n",
      "test_correct: 0.5959; test_loss: 2.656430376768112\n",
      "Client Index = 0\tEpoch: 183\tLoss: 0.215241\n",
      "test_correct: 0.5926; test_loss: 2.736703808307648\n",
      "Client Index = 0\tEpoch: 184\tLoss: 0.228763\n",
      "test_correct: 0.5958; test_loss: 2.671827301979065\n",
      "Client Index = 0\tEpoch: 185\tLoss: 0.220408\n",
      "test_correct: 0.5949; test_loss: 2.7510098123550417\n",
      "Client Index = 0\tEpoch: 186\tLoss: 0.211218\n",
      "test_correct: 0.5943; test_loss: 2.740074688196182\n",
      "Client Index = 0\tEpoch: 187\tLoss: 0.189292\n",
      "test_correct: 0.5983; test_loss: 2.6710715925693513\n",
      "Client Index = 0\tEpoch: 188\tLoss: 0.193328\n",
      "test_correct: 0.5933; test_loss: 2.7494729471206667\n",
      "Client Index = 0\tEpoch: 189\tLoss: 0.190445\n",
      "test_correct: 0.5958; test_loss: 2.721678035259247\n",
      "Client Index = 0\tEpoch: 190\tLoss: 0.182518\n",
      "test_correct: 0.594; test_loss: 2.724742249250412\n",
      "Client Index = 0\tEpoch: 191\tLoss: 0.189836\n",
      "test_correct: 0.5933; test_loss: 2.754513980150223\n",
      "Client Index = 0\tEpoch: 192\tLoss: 0.173974\n",
      "test_correct: 0.5943; test_loss: 2.7494108653068543\n",
      "Client Index = 0\tEpoch: 193\tLoss: 0.191314\n",
      "test_correct: 0.5937; test_loss: 2.7604987370967864\n",
      "Client Index = 0\tEpoch: 194\tLoss: 0.195975\n",
      "test_correct: 0.5947; test_loss: 2.747600873708725\n",
      "Client Index = 0\tEpoch: 195\tLoss: 0.192959\n",
      "test_correct: 0.595; test_loss: 2.7321290731430055\n",
      "Client Index = 0\tEpoch: 196\tLoss: 0.198591\n",
      "test_correct: 0.5962; test_loss: 2.729154043197632\n",
      "Client Index = 0\tEpoch: 197\tLoss: 0.208721\n",
      "test_correct: 0.5952; test_loss: 2.72631257891655\n",
      "Client Index = 0\tEpoch: 198\tLoss: 0.203490\n",
      "test_correct: 0.5963; test_loss: 2.7310639667510985\n",
      "Client Index = 0\tEpoch: 199\tLoss: 0.192624\n",
      "test_correct: 0.5961; test_loss: 2.7147973477840424\n"
     ]
    }
   ],
   "source": [
    "train_model(client_1, 200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
