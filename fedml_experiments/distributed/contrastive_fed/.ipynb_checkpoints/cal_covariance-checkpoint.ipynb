{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "951fc0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import argparse\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"./../../../../\")))\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"./../../../\")))\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82e0234f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedml_api.data_preprocessing.cifar10.data_loader import load_partition_data_cifar10\n",
    "from fedml_api.standalone.fedavg.my_model_trainer_classification import MyModelTrainer as MyModelTrainerCLS\n",
    "from fedml_api.model.contrastive_cv.resnet_with_embedding import Resnet56\n",
    "from CovaMNet import CovaMResnet56\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from collections import OrderedDict\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "# from triplet_loss import TripletLoss\n",
    "from hard_triplet_loss import TripletLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d85b0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'cifar10'\n",
    "data_dir = \"./../../../data/cifar10\"\n",
    "# partition_method = 'hetero'\n",
    "partition_method = 'homo'\n",
    "partition_alpha = 0.5\n",
    "client_num_in_total = 3\n",
    "batch_size = 64\n",
    "total_epochs = 500\n",
    "\n",
    "save_model_path = 'model/cs_{0}_{1}_client_{2}_identity_mean_covaM_epochs_{3}.pt'\n",
    "\n",
    "device = 'cuda:0'\n",
    "with_cova = True\n",
    "\n",
    "with open(f'dataset_{partition_method}_{client_num_in_total}.pickle', 'rb') as f:\n",
    "    dataset = pickle.load(f)\n",
    "# [train_data_num, test_data_num, train_data_global, test_data_global, \\\n",
    "# #             train_data_local_num_dict, train_data_local_dict, test_data_local_dict, \\\n",
    "# #             class_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1537b43b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Resnet56(class_num=dataset[-1], neck='bnneck')\n",
    "model.load_state_dict(torch.load('model/cs_3_homo_client_0_oral_epochs_200.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9f95cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([6, 0, 2, 9, 4, 1, 3, 7, 5, 8])\n"
     ]
    }
   ],
   "source": [
    "data_dict = {}\n",
    "for batch_idx, (imgs, labels) in enumerate(dataset[5][2]):\n",
    "    for x, l in zip(imgs, labels):\n",
    "        label = int(l.data)\n",
    "        if label not in data_dict.keys():\n",
    "            data_dict[label] = []\n",
    "        else:\n",
    "            if len(data_dict[label]) < 10:\n",
    "                data_dict[label].append(x)\n",
    "print(data_dict.keys())\n",
    "with open(f'data_dict.pickle', 'wb') as f:\n",
    "    pickle.dump(data_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ad43ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k,v in data_dict.items():\n",
    "#     print(len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cdca50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_covariance(input):\n",
    "\n",
    "#     CovaMatrix_list = []\n",
    "#     mean_list = []\n",
    "    B, C, h, w = input.size()\n",
    "    print(B)\n",
    "    support_set_sam = input.permute(1, 0, 2, 3)\n",
    "    support_set_sam = support_set_sam.contiguous().view(C, -1)\n",
    "    \n",
    "    mean_support = torch.mean(support_set_sam, 1, True)\n",
    "#     mean_list.append(mean_support)\n",
    "    \n",
    "    support_set_sam = support_set_sam-mean_support\n",
    "    \n",
    "    covariance_matrix = support_set_sam@torch.transpose(support_set_sam, 0, 1)\n",
    "    covariance_matrix = torch.div(covariance_matrix, h*w*B-1)\n",
    "    \n",
    "    return covariance_matrix, mean_support\n",
    "    \n",
    "#     for i in range(len(input)):\n",
    "#         support_set_sam = input[i]\n",
    "#         support_set_sam = torch.unsqueeze(support_set_sam, 0)\n",
    "#         B, C, h, w = support_set_sam.size()\n",
    "#         print(B)\n",
    "\n",
    "#         support_set_sam = support_set_sam.permute(1, 0, 2, 3)\n",
    "#         support_set_sam = support_set_sam.contiguous().view(C, -1)\n",
    "\n",
    "#         mean_support = torch.mean(support_set_sam, 1, True)\n",
    "#         mean_list.append(mean_support)\n",
    "\n",
    "#         support_set_sam = support_set_sam-mean_support\n",
    "\n",
    "#         covariance_matrix = support_set_sam@torch.transpose(support_set_sam, 0, 1)\n",
    "#         covariance_matrix = torch.div(covariance_matrix, h*w*B-1)\n",
    "# #         CovaMatrix_list.append(covariance_matrix)\n",
    "\n",
    "#     return covariance_matrix, mean_list\n",
    "        \n",
    "        \n",
    "\n",
    "# cl = [torch.zeros((256,256)) for i in range(10)]\n",
    "# ml = [torch.zeros((256,64)) for i in range(10)]\n",
    "# lbd = 0.999\n",
    "# labels = []\n",
    "cova_list = [0 for i in range(10)]\n",
    "mean_list = [0 for i in range(10)]\n",
    "def extract_features(model, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    features = []\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for k, v in data_dict.items():\n",
    "            x = torch.stack(data_dict[k]).to(device)\n",
    "#             print(x.shape)\n",
    "            score, feats = model(x)\n",
    "            covariance_matrix, mean_support = cal_covariance(feats)\n",
    "            cova_list[k] = covariance_matrix\n",
    "            mean_list[k] = mean_support\n",
    "#             cova_list.append(covariance_matrix)\n",
    "#             mean_list.append(mean_support)\n",
    "#             print(covariance_matrix)\n",
    "#             print(mean_support)\n",
    "#             break\n",
    "#         for batch_idx, (x, l) in enumerate(data_loader):\n",
    "#             x, l = x.to(device), l.to(device)\n",
    "            \n",
    "#             score, feats = model(x)\n",
    "#             covaM_list, mean_list = cal_covariance(feats)\n",
    "#             for covaM, f, label in zip(covaM_list, feats, l):\n",
    "#                 labels.append(label.cpu())\n",
    "#                 for i in range(len(cl)):\n",
    "#                     if label.data.cpu() == i:\n",
    "#                         cl[i] = lbd * cl[i] + (1-lbd) * covaM.cpu()\n",
    "#                         f = torch.unsqueeze(f, 0)\n",
    "#                         B, C, h, w = f.size()\n",
    "\n",
    "#                         f = f.permute(1, 0, 2, 3)\n",
    "#                         f = f.contiguous().view(C, -1)\n",
    "#                         ml[i] = lbd * ml[i] + (1-lbd) * f.cpu()\n",
    "\n",
    "# # metrics = test(model, dataset[3], device)\n",
    "# # test_correct = metrics['test_correct']/metrics['test_total']\n",
    "# # test_loss = metrics['test_loss']/metrics['test_total']\n",
    "# # print(metrics['test_total'])\n",
    "# # print(f'test_correct: {test_correct}; test_loss: {test_loss}')\n",
    "extract_features(model, device)\n",
    "# # covaMs_means = [cl, ml]\n",
    "# # with open(f'class_covaMs_means.pickle', 'wb') as f:\n",
    "# #     pickle.dump(covaMs_means, f)\n",
    "# print(len(cova_list))\n",
    "# print(sum(cova_list) / len(cova_list))\n",
    "# print(len(mean_list))\n",
    "# print(sum(mean_list) / len(mean_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94010577",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(cova_list))\n",
    "print(cova_list[0])\n",
    "print(len(mean_list))\n",
    "print(mean_list[0])\n",
    "\n",
    "covaMs_means = [cova_list, mean_list]\n",
    "\n",
    "with open(f'new_covaM_mean.pickle', 'wb') as f:\n",
    "    pickle.dump(covaMs_means, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
